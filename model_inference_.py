# -*- coding: utf-8 -*-
"""model_inference..ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18l-Necpk63gLRrMX3kd_t7SzqERH41Iu
"""

import tensorflow as tf
from transformers import BertTokenizer, TFBertModel
import pandas as pd

def custom_object_scope():
    return {
        'TFBertModel': TFBertModel
    }

with tf.keras.utils.custom_object_scope(custom_object_scope()):
    loaded_model = tf.keras.models.load_model("model.h5")

tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
def text_preprocessing(text:str):
  tokenized_text = tokenizer.tokenize(text)
  input_ids = tokenizer.convert_tokens_to_ids(tokenized_text)
  return input_ids

test = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/task1/test.csv")

input_ids_test = [text_preprocessing(text) for text in test['text']]
max_inner_length_test = 48
attention_masks_test = []

for ids in input_ids_test:
    attention_mask = [1] * len(ids) + [0] * (max_inner_length_test - len(ids))
    attention_masks_test.append(attention_mask)

attention_masks_tensor_test = tf.constant(attention_masks_test, dtype=tf.int32)
input_ids_test = tf.keras.preprocessing.sequence.pad_sequences(input_ids_test, maxlen=max_inner_length_test, padding='post', truncating='post')

predictions_test = loaded_model.predict([input_ids_test, attention_masks_tensor_test])
predicted_labels_test = (predictions_test > 0.5).astype(int)
from sklearn.metrics import classification_report


true_labels_test = test['label']

print(classification_report(true_labels_test, predicted_labels_test))