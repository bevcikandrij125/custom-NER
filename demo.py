# -*- coding: utf-8 -*-
"""demo.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fB3RLKajm_HvZ1TxfigSKq5D026We08f
"""

import tensorflow as tf
from transformers import BertTokenizer, TFBertModel
import pandas as pd
from tensorflow.keras.utils import get_file

def custom_object_scope():
    return {
        'TFBertModel': TFBertModel
    }
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
with tf.keras.utils.custom_object_scope(custom_object_scope()):
    loaded_model = tf.keras.models.load_model("model.h5")

from tensorflow.keras.preprocessing.sequence import pad_sequences

def predict(word, context, max_inner_length=48):
    text = f"{word} token_of_sentence {context}"
    tokenized_text = tokenizer.tokenize(text)
    input_ids = tokenizer.convert_tokens_to_ids(tokenized_text)

    # Add padding
    input_ids = pad_sequences([input_ids], maxlen=max_inner_length, padding='post', truncating='post')[0]

    attention_mask = [1] * len(input_ids)

    predictions = loaded_model.predict([tf.constant([input_ids]), tf.constant([attention_mask])])
    predicted_label = int(predictions[0][0] > 0.5)

    return predicted_label

def process_and_modify(text):
    words = text.split()
    modified_tokens = []
    previous = False
    for word in words:
        prediction = predict(word, text)
        if prediction == 1:
          if not previous:
            modified_tokens.append(f"{{Mountain:{word}")
          if previous:
             modified_tokens.append(f"{word}")
        else:
            if previous:
              modified_tokens.append(word + "}")
            modified_tokens.append(word)
        previous = prediction
    return ' '.join(modified_tokens)

input = """Visiting Crimea, decided not to settle for the ordinary! Climbing a mountain?
 No, this time opted for  Swiss Alps   deep and mysterious valleys of the Crimean mountains.
 Discovering new corners of beauty and tranquility!"""

print(process_and_modify(input))